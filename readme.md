### Intro:

I have created a repository where I have employed and learned various tools that have proven to be invaluable in the field of data science. These tools are organized into the following steps of the data science process:

1. Discover the Data: Techniques for exploring and understanding the dataset, including data visualization and exploration tools.

2. Get the Data: This step involves collecting and acquiring the necessary data from various sources. It includes the following methods:

    *   Web Scraping: Utilize the **BeautifulSoup** library to extract data from the web.
    *   PDF Scraping: Extract tables from PDFs and work with them directly using **Tabula** Library.
    *   Wikipedia Library: Extract data from **Wikipedia** Library.
    *   GPS Location: Obtain location details using **Geocoder** Library.
   
   You can find practical experiment in the "getting-data" folder

3. Prepare the Data: Tools for data cleaning, preprocessing, and transforming raw data into a suitable format for analysis.

4. Model the Data: In this step, we apply various algorithms and techniques to construct predictive or descriptive models. Practical modeling approaches in our project include:

    *   Clustering: Applied to the stock market dataset for data grouping and pattern identification.
    *   Forecasting with ARIMA: Employed to predict new death cases in the COVID-19 dataset.
    *   Pycaret: Utilized on an inbuilt dataset to understand how Pycaret runs multiple models simultaneously and identifies the best-performing model.
    *   Decision Tree: Developed decision tree models for classification tasks.
    *   TextBlob: Conducted sentiment analysis using TextBlob.

You can find these models in the "ML-Models" folder


5. Modern Deep Learning Tools: Exploring contemporary tools and frameworks for deep learning applications.

6. Analyze / Visualize the Output: This stage involves strategies for effectively visualizing and presenting the results of data analysis. Some of the tools and techniques used include:

    *   Pandas Profile: Utilized to generate comprehensive reports on datasets.
    *   Folium with geopy.distance: Applied for geospatial analysis to support decision-making, such as determining suitable locations for new restaurants or retail stores.

You can find practical experiment in the "analysis_output" folder


7. Narrate a Story: Techniques for storytelling with data, which involves communicating insights and findings to stakeholders.



8. Deploy Tools: Methods for deploying data science solutions into production environments.
   *   Heroku 
   *   Streamlit
   
   I have utilized these deployment tools for other codes.






